{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_english(filename):\n",
    "    file = open(filename, encoding='utf-8')\n",
    "    toReturn = []\n",
    "    for phrase in file:\n",
    "        toAdd = phrase.split()\n",
    "        toAdd.insert(0, \"*\")\n",
    "        toReturn.append(toAdd)\n",
    "    return toReturn\n",
    "\n",
    "def read_spanish(filename):\n",
    "    file = open(filename, encoding='utf-8')\n",
    "    toReturn = []\n",
    "    toRemove = []\n",
    "    for phrase in file:\n",
    "        toReturn.append(phrase.split())\n",
    "    i = 0\n",
    "    for phrase in toReturn:\n",
    "        if len(phrase) == 0:\n",
    "            toRemove.append(i)\n",
    "        i += 1\n",
    "    return toReturn, toRemove\n",
    "\n",
    "print(\"Reading in corpus data...\\n\")\n",
    "english = read_english(\"corpus.en\")\n",
    "spanish, remove = read_spanish(\"corpus.es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Removing null phrases...\\n\")\n",
    "for none in sorted(remove, reverse=True):\n",
    "    del english[none]\n",
    "    del spanish[none]\n",
    "print(\"English dataset is \" + str(len(english)))\n",
    "print(\"Spanish dataset is \" + str(len(spanish)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_words = []\n",
    "spanish_words = []\n",
    "english_index={}\n",
    "spanish_index={}\n",
    "print(\"Collecting words and indices...\\n\")\n",
    "for i in range(len(english)):\n",
    "    for eword in english[i]:\n",
    "        if eword not in english_words:\n",
    "            english_words.append(eword)\n",
    "    for sword in spanish[i]:\n",
    "        if sword not in spanish_words:\n",
    "            spanish_words.append(sword)\n",
    "    for i in range(len(english_words)):\n",
    "        english_index[english_words[i]] = i\n",
    "    for i in range(len(spanish_words)):\n",
    "        spanish_index[spanish_words[i]] = i    \n",
    "print(\"Spanish words are \" + str(len(spanish_words)))\n",
    "print(\"English words are \" + str(len(english_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating first generation t numbers...\\n\")\n",
    "count = {}\n",
    "base_t=[]\n",
    "parallel = zip(english, spanish)\n",
    "visited = set()\n",
    "for f, s in parallel:\n",
    "    for f_j in f:\n",
    "        for s_i in s:\n",
    "            pair = (f_j, s_i)\n",
    "            if pair not in visited:\n",
    "                visited.add(pair)\n",
    "                if not f_j in count:\n",
    "                    count[f_j] = 0\n",
    "                count[f_j] += 1\n",
    "                \n",
    "for i in english_words:\n",
    "    base_t.append(1/ count[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "t_params = sp.dok_matrix((len(english_words), len(spanish_words)), dtype=np.float32)\n",
    "\n",
    "def delta(i, k):\n",
    "    spanish_word = spanish[k][i];\n",
    "    num = []\n",
    "    summation=0\n",
    "    for word in range(len(english[k])):\n",
    "        english_word= english[k][word]\n",
    "        p_1 = english_index[english_word]\n",
    "        p_2 = spanish_index[spanish_word]\n",
    "        temp = t_params[p_1, p_2]\n",
    "        if temp == 0:\n",
    "            temp_index = english_index[english_word]\n",
    "            temp= base_t[temp_index]\n",
    "        summation += temp\n",
    "        num.append(temp)\n",
    "    return np.array(num)/summation\n",
    "\n",
    "def t(counts):\n",
    "    r = counts.sum(1)\n",
    "    #print(r)\n",
    "    return counts/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "print(\"Generating t parameters...\\n\")\n",
    "t_params = sp.dok_matrix((len(english_words), len(spanish_words)), dtype=np.float32)\n",
    "n = 5\n",
    "for iteration in range(n):\n",
    "    print(str(iteration) + \" out of \" + str(n) + \" iterations\")\n",
    "    temp = sp.dok_matrix((len(english_words), len(spanish_words)), dtype=np.float32)\n",
    "    for k in range(len(english)): \n",
    "        for i in range(len(spanish[k])):\n",
    "            d = delta(i, k)\n",
    "            f_w = spanish[k][i]\n",
    "            f_i = spanish_index[f_w]\n",
    "            for j in range(len(english[k])):\n",
    "                e_w = english[k][j]\n",
    "                e_i = english_index[e_w]\n",
    "                temp[e_i, f_i] += d[j]\n",
    "    t_params=t(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving the t parameters...\\n\")\n",
    "#print(type(t_params))\n",
    "#print(t_params.shape)\n",
    "np.savetxt('t_params.txt', t_params, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading dev data corpus...\\n\")\n",
    "english_file = open('dev.en', encoding='utf-8')\n",
    "spanish_file = open('dev.es', encoding='utf-8')\n",
    "e_dev = []\n",
    "s_dev = []\n",
    "for phrase in english_file:\n",
    "    e_dev.append(phrase.split())\n",
    "for phrase in spanish_file:\n",
    "    s_dev.append(phrase.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open(\"out.key\", \"w\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start generating key with dev data...\\n\")\n",
    "for i in range(len(s_dev)):\n",
    "    for s_i_dev,s_w_dev in enumerate(s_dev[i],1):\n",
    "        if s_w_dev in spanish_words:\n",
    "            max = 0\n",
    "            s_index = spanish_index[s_w_dev]\n",
    "            predicted_index=0\n",
    "            for e_i_dev,e_w_dev in enumerate(e_dev[i],1):\n",
    "                e_index= english_index[e_w_dev] \n",
    "                if t_params[e_index,s_index]==0:\n",
    "                    value = base_t[e_index]\n",
    "                else:\n",
    "                    value = t_params[e_index,s_index]\n",
    "                if value > max:\n",
    "                    max= value; \n",
    "                    predicted_index = e_i_dev\n",
    "            outfile.write(str(i+1)+' '+str(predicted_index)+' '+str(s_i_dev)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile.close()\n",
    "print(\"Evaluating...\\n\")\n",
    "os.system(\"python eval_alignment.py dev.key out.key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!python eval_alignment.py 'dev.key' 'out.key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
